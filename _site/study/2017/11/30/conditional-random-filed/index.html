<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      CRF(Conditional Random Field) &middot; 1SoulJo
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <!-- <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png"> -->
  <link rel="shortcut icon" href="https://smilebasicsource.com/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
          <img src="/public/img/maschine.jpg"/>
      </div>
      <div class="sidebar-personal-info-section">
        <p><strong>developer</strong></p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me:
        
        
        
        <a href="https://github.com/1souljo">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:hansol.jo@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

    <!-- <span class="sidebar-nav-item">Currently v1.0.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2017 1SoulJo. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a> and <a href="http://codinfox.github.io">codinfox-lanyon</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home" title="1SoulJo">
              1SoulJo
            </a>
            <small>technical blog and study</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">CRF(Conditional Random Field)</h1>
  <span class="post-date">30 Nov 2017</span>
   | 
  
    <a href="/blog/tags/#crf" class="post-tag">CRF</a>
  
  
  <article>
    <h2 id="crf-란">CRF 란?</h2>
<p>저스틴 비버의 하루 일상을 순서대로 찍은 사진들이 있다고 상상해보자.<br />
우리는 각각의 사진에 한 단어로 설명(라벨)을 달고자 한다. (예&gt; 식사 사진, 수면 사진, 운전 중 등등)<br />
어떻게 하면 될까?</p>

<p>한가지 방법은 사진들이 가지는 순서에 대한 정보는 무시하고 각 사진 자체만으로 분류를 해보는 것이 될 수 있겠다.
예를 들어 라벨이 달린 한 달 치의 사진이 주어졌다고 하면, 아침 6시 쯤에 찍힌 어두운 사진들은 ‘수면’ 과 연관이 있는 사진들이고,
밝은 색깔이 많이 포함된 사진은 ‘춤’ 에 대한 사진, 자동차가 나온 사진들은 ‘운전’ 사진이라는 등의 사실을 배울 수 있을 것이다.</p>

<p>하지만 순서에 대한 관점을 무시하면 많은 양의 정보를 잃게 된다. 예를 들어 입만 크게 나온 사진이 있다고 하자. 그건 노래하는 사진일까 밥 먹는 사진일까?
만약 이전의 사진이 저스틴 비버가 밥을 먹거나 요리하는 사진이었다면, 그 입 사진은 ‘먹는’ 행위에 관한 사진일 가능성이 더 높을 것이다.
하지만 이전 사진이 저스틴 비버가 노래나 춤 추는 사진이었다면, 입 사진도 마찬가지로 ‘노래하는’ 사진일 가능성이 높다.</p>

<h3 id="part-of-speech-tagging">Part-of-Speech Tagging</h3>
<p>part-of-speech tagging 를 예로 좀 더 자세히 살펴보도록 하자.<br />
POS tagging 의 목적은 한 문장의 어휘들의 품사를 달아주는 것이다. (ex&gt; 명사, 동사, 형용사, 명사)<br />
예를 들어 ‘Bob drank coffee at Starbucks.’ 라는 문장은 ‘Bob(명사) drank(동사) coffee(명사) at(전치사) Starbucks(명사)’ 가 될 것이다.
그럼 이제 CRF 를 이용해서 POS tagging 을 해보자. 먼저 다른 classifier 들과 마찬가지로 feature function <script type="math/tex">f_i</script> 들을 정의해야 한다.</p>

<h3 id="feature-functions-in-a-crf">Feature functions in a CRF</h3>
<p>CRF 에서 각각의 feature function 은 아래와 같은 입력들을 받는 함수이다:</p>
<ul>
  <li>s : 문장</li>
  <li>i : 단어의 문장 내 인덱스</li>
  <li><script type="math/tex">l_i</script> : 현재 단어의 라벨</li>
  <li><script type="math/tex">l_{i-1}</script> : 이전 단어의 라벨</li>
</ul>

<p>그리고 출력 값은 실수 값이 된다.(하지만 실제로는 0 또는 1 인 경우가 많다.)</p>

<p><em>참고 : 본 포스팅에서는 문장 전체에 대한 라벨이 아니라 현재 단어와 이전 단어의 라벨만 사용하도록 제한하고 있다.
이것은 <strong>linear-chain CRF</strong> 의 일종이라고 할 수 있다. 설명의 편의를 위해 범용적인 CRF 에 대한 내용은 생략하고자 한다.</em></p>

<h3 id="feature-를-probabilties-로">Feature 를 Probabilties 로.</h3>
<p>이제 각각의 feature function <script type="math/tex">f_j</script> 에 weight <script type="math/tex">\lambda_j</script> 를 할당해 보자.(데이터로부터 이 weight 들을 어떻게 학습하는 지는 아래에 설명하겠다.)<br />
문장 s 가 주어졌을 때, 문장 내 모든 단어에 대한 weighted feature 값을 더하여 s 에 라벨 l 이 부여될 수 있는지 점수를 매길 수 있다.</p>

<script type="math/tex; mode=display">score(l|s) = \sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})</script>

<p>(첫 번째 시그마는 각각의 feature function <script type="math/tex">f</script> 에 대한 것이고, 안쪽 시그마는 <script type="math/tex">i</script> 위치의 단어 각각에 대한 연산이다.)</p>

<p>그 다음 지수 연산(exponentiating)과 정규화(normalizing)를 통해 이 점수를 확률
<script type="math/tex">p(l | s)</script> 로 환산할 수 있다.</p>

<script type="math/tex; mode=display">p(l | s) = \frac{exp[score(l|s)]}{\sum_{l’} exp[score(l’|s)]} = \frac{exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})]}{\sum_{l’} exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l’_i, l’_{i-1})]}</script>

<h3 id="feature-function-예시">Feature Function 예시</h3>
<p>그럼 이 feature function 들은 어떻게 생겼을까? POS tagging 의 feature 들은 다음과 같을 수 있다:</p>
<ul>
  <li>
    <script type="math/tex; mode=display">% <![CDATA[
f_1(s, i, l_i, l_{i-1}) =
\begin{cases}
 1 & \mbox{if }l_i = \text{부사(ADVERB)} \mbox{ and the ith word ends in “-ly”} \\
 0 & \mbox{otherwise.}
 \end{cases} %]]></script>
    <ul>
      <li>이 feature 에 대한 weight <script type="math/tex">\lambda_1</script> 값이 양수이고 큰 경우, 이 feature 는 -ly 로 끝나는 단어를 ‘부사’ 로 라벨링할 거라는 의미가 될 것이다.</li>
    </ul>
  </li>
  <li>
    <script type="math/tex; mode=display">% <![CDATA[
f_2(s, i, l_i, l_{i-1}) =
\begin{cases}
1 & \mbox{if } i = 1, l_i = 동사(VERB), \mbox{ and the sentence ends in a question mark} \\
0 & \mbox{otherwise.}
\end{cases} %]]></script>
    <ul>
      <li>마찬가지로 feature 에 대한 weight <script type="math/tex">\lambda_2</script> 값이 양수이고 큰 경우, ? 로 끝나는 문장의 첫 단어를 ‘동사’ 로 라벨링하고자 할 것이다.</li>
    </ul>
  </li>
  <li>
    <script type="math/tex; mode=display">% <![CDATA[
f_3(s, i, l_i, l_{i-1}) =
\begin{cases}
1 & \mbox{if }l_{i-1} = \mbox{형용사(ADJECTIVE)} \mbox{, and }l_i = \mbox{명사(NOUN)} \\
0 & \mbox{otherwise.}
\end{cases} %]]></script>
    <ul>
      <li>weight 가 양수 인 경우, 이 feature 는 형용사 뒤에는 명사가 온다는 것을 의미한다.</li>
    </ul>
  </li>
  <li>
    <script type="math/tex; mode=display">f_4(s, i, l_i, l_{i-1}) = 1 \mbox{ if }l_{i-1} =\mbox{ 전치사(PREPOSITION) and }l_i = \mbox{전치사(PREPOSITION).}</script>
    <ul>
      <li>이 함수에 대한 음수의 weight <script type="math/tex">\lambda_4</script> 는 전치사 뒤에는 전치시가 오면 안되다는 것을 의미한다. 따라서 그런 라벨링이 발생하지 않도록 할 수 있을 것이다.</li>
    </ul>
  </li>
</ul>

<p>이게 끝이다!<br />
정리해보면 CRF 를 만들기 위해서는,</p>
<ol>
  <li>feature function 몇 개를 정의해주고, (feature function 은 전체 문장, 현재 위치, 그리고 주변의 라벨 값을 참조한다.)</li>
  <li>weight 를 할당하고</li>
  <li>전체를 몽땅 더한 다음,</li>
  <li>필요하면 그 값을 확률로 환산하면 된다.</li>
</ol>

<p>이제 CRF 이 다른 머신 러닝 기술들와 어떻게 다른지 비교해보도록 하자.</p>

<h2 id="smells-like-logistic-regression">Smells like Logistic Regression…</h2>
<p>CRF 의 아래 식은 왠지 친숙해 보일 수도 있다. <em><a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank">궁금하면 여기</a></em></p>

<script type="math/tex; mode=display">p(l | s) = \frac{exp[\sum_{j = 1}^m \sum_{i = 1}^n f_j(s, i, l_i, l_{i-1})]}{\sum_{l’} exp[\sum_{j = 1}^m \sum_{i = 1}^n f_j(s, i, l’_i, l’_{i-1})]}</script>

<p>왜냐하면 CRF 는 근본적으로 Logistic Regression 의 순차 버전(sequential version)이기 때문이다.</p>
<blockquote>

  <p>Logistic Regression 이 분류(claasification) 을 위한 log-linear 모델인데 반해,<br />
CRF 는 순차적인 라벨링(sequential labels) 을 위한 log-linear 모델이다.</p>
</blockquote>

<h2 id="looks-like-hmms">Looks like HMMs…</h2>
<p>HMM(<a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" target="_blank">Hidden Markov Model</a>) 도 POS tagging(또한 일반적인 순차 라벨링) 에 사용될 수 있는 모델임을 기억하자.<br />
CRF 가 라벨링 점수를 계산하기 위해 여러 개의 feature function 을 다 같이 사용하는데 비해,<br />
HMM 은 라벨링을 위해 생성적(generative) 방식을 취한다. 그 식은 아래와 같다:</p>

<script type="math/tex; mode=display">p(l,s) = p(l_1) \prod_i p(l_i | l_{i-1}) p(w_i | l_i)</script>

<p>이 때,</p>
<ul>
  <li>$
p(l_i | l_{i-1})$ 는 전이 확률(transition probabilities) - 예&gt; 전치사 뒤에 명사가 나올 확률</li>
  <li>$
p(w_i | l_i)$ 는 출력 확률(emission probabilities) - 예&gt; ‘명사’ 라벨이 ‘아빠’ 를 도출할 확률</li>
</ul>

<p>그럼 HMM 과 CRF 는 어떻게 다른가?<br />
<strong>CRF 가 더 강력하다!</strong><br />
CRF 는 HMM 이 할 수 있는 모든 것을 모델링할 수 있고, 그것보다 더 많은 일을 해낸다. 왜 그런지는 아래를 살펴보자.</p>

<p>HMM 확률 식에 log 를 취하면 아래와 같다.</p>

<script type="math/tex; mode=display">\log p(l,s) = \log p(l_0) + \sum_i \log p(l_i | l_{i-1}) + \sum_i \log p(w_i | l_i)</script>

<p>이 log-확률을 2진(binary) 전이, 출력 feature 들에 할당된 weight 라고 간주하면, 위 식은 CRF 의 log-linear 형태와 완전히 일치한다.
다시 말해, 어떠한 HMM 이라도 그와 동일한 CRF 를 구현할 수 있다는 뜻이다. 그 방법은 아래와 같다.</p>

<ul>
  <li>HMM 의 전이 확률 $p(l_i = y | l_{i-1} = x)$ 각각에 대해 CRF 전이 feature 를 아래처럼 정의한다.<br />
$f_{x,y}(s, i, l_i, l_{i-1}) = 1 \text{ if }l_i = y \text{, and }l_{i-1} = x$<br />
그리고 각 feature 에 다음과 같은 weight 를 부여한다.<br />
$w_{x,y} = \log p(l_i = y | l_{i-1} = x)$</li>
  <li>위와 유사하게, HMM 의 출력 확률 $p(w_i = z | l_{i} = x)$ 각각에 대해 CRF 출력 feature 를 아래처럼 정의한다.<br />
$g_{x,y}(s, i, l_i, l_{i-1}) = 1 \text{ if }w_i = z\text{, and }l_i = x$<br />
그리고 각 feature 에 다음과 같은 weight 를 부여한다.<br />
$w_{x,z} = \log p(w_i = z | l_i = x)$</li>
</ul>

<p>그러면 이 feature function 들을 사용하여 계산된 <script type="math/tex">p(l|s)</script> 점수는 해당하는 HMM 에 의해 계산된 점수에 정확히 비례하게 되고, 따라서 모든 HMM 은 특정 CRF 로 표현이 가능해진다.</p>

<p>하지만 CRF 훨씬 풍부한 라벨 분포 set 를 모델링할 수 있는데, 이 이유는 다음과 같다.</p>
<ul>
  <li><strong>CRF 는 훨씬 많은 수의 feature set 를 정의할 수 있다.</strong> HMM 은 태생적으로 지엽적(local) 속성을 가진다.
왜냐면 HMM 은 2진 전이, 출력 feature function 만 사용 가능하고, 이로 인해 각 단어는 오직 현재의 라벨에, 그리고 각 라벨은 바로 이전의 라벨에만 의존하게 되기 때문이다.
이에 반해 CRF 는 좀더 전역적(global) feature 들을 사용할 수 있다. 예를 들어 위에서 보여준 POS tagger 의 feature 들 중 하나는 <em>문장의 끝이 ? 인 경우
문장의 제일 첫 단어가 동사</em> 로 태깅될 확률을 높이고 있다.</li>
  <li><strong>CRF 는 임의(arbitrary)의 weight 값들을 가질 수 있다.</strong> HMM 의 확률 값들은 어떤 조건 - 예를 들면,  $
0 &lt;= p(w_i | l_i) &lt;= 1, \sum_w p(w_i = w | l_1) = 1)$ - 을 반드시 충족시켜야만 한다. 그에 비해 CRF 의 weight 는 아무 제약이 없다.<br />
$\log p(w_i | l_i)$ 는 어떠한 값이든 될 수 있다.</li>
</ul>

<h3 id="weight-의-학습">Weight 의 학습</h3>
<p>CRF 에서 weight 를 어떻게 학습시키는지에 대한 질문으로 다시 되돌아가자. <strong>gradient ascent (짜잔)</strong> 를 사용하는 것이 하나의 방법이 될 수 있다.</p>

<p>학습 데이터(문장들과 그에 대한 POS 라벨들)가 충분히 있다고 가정해보자. 먼저 CRF 모델의 weight 들을 임의의 값으로 초기화 한다.
이 무작위 weight 값들을 정답으로 바꿔나가려면 각각의 학습 데이터에 다음과 같은 작업을 해주면 된다.</p>
<ul>
  <li>각각의 feature function <script type="math/tex">f_i</script> 에서 학습 데이터의 log 확률에 대한 gradient 를 계산한다.
<script type="math/tex">\lambda_i \text{ : }\frac{\partial}{\partial w_j} \log p(l | s) = \sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l’} p(l’ | s) \sum_{j = 1}^m f_i(s, j, l’_j, l’_{j-1})</script></li>
  <li>gradient 의 첫 번째 term 은 <em>true</em> 라벨을 갖는 feature <script type="math/tex">f_i</script> 의 분포를,
 두 번째 term 은 현재 모델에서 feature <script type="math/tex">f_i</script> 의 <em>expected</em> 값의 분포를 나타냄을 주목하자.</li>
  <li><script type="math/tex">\lambda_i</script> 를 gradient 방향으로 이동시킨다 :<br />
<script type="math/tex">\lambda_i = \lambda_i + \alpha [\sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l’} p(l’ | s) \sum_{j = 1}^m f_i(s, j, l’_j, l’_{j-1})]</script> where $\alpha$ is some learning rate.</li>
  <li>특정 조건(더 이상 갱신이 안된다던가)에 도달할 때까지 위의 작업을 반복한다.</li>
</ul>

<h3 id="최적-라벨-찾기">최적 라벨 찾기</h3>
<p>우리의 CRF 모델을 학습시켰고 이제 새로운 문장이 입력된다고 생각해보자. 라벨링은 어떻게 되나?</p>

<p>단순한 방법은 모든 가능한 라벨 l 에 대한 <script type="math/tex">p(l | s)</script> 를 계산하고, 이 확률을 최대화 시키는 라벨을 고르는 것이 될테다.
하지만 m 길이의 문장과 k 개의 tag 셋이 있다면 총 <script type="math/tex">k^m</script> 개의 조합이 가능하기 때문에, 이 방식은 지수승의 연산을 필요로 한다.</p>

<p>더 좋은 방법이 있다. (linear-chain) CRF 는 <a href="https://en.wikipedia.org/wiki/Optimal_substructure" target="_blank">optimal substructure</a> 속성을 만족하기 때문에, (polynomial-time 복잡도의) 동적 프로그래밍 알고리즘으로 최적 라벨을 찾을 수 있다. 이는 HMM 에 <a href="http://en.wikipedia.org/wiki/Viterbi_algorithm" target="_blank">Viterbi 알고리즘</a>을 적용하는 것과 유사하다.</p>

<h3 id="좀-더-재밌는-응용">좀 더 재밌는 응용</h3>
<p>사실 part-of-speech tagging 은 좀 지루하고, 다른 POS 태거도 이미 많다. 실 생활에서 CRF 는 어디다가 써먹을 수 있을까?</p>

<p>트위터에서 사람들이 크리스마스에 받은 선물의 타입을 마이닝하고 싶다. 고 해보자.</p>

<p><img src="/public/img/CRF_Twitter.jpg" alt="twitter" /></p>

<p>그러면 문장에서 어느 단어가 선물에 해당하는지 어떻게 찾아낼 수 있나??!!1</p>

<p>위와 같은 그래프를 만들기 위해 나는 그냥 “크리스마스에 XXX 가 갖고싶어요.” 와 “크리스마스에 XXX 를 받았어요!” 형태의 문장을 검색했을 뿐이다.
하지만 더 세련된 CRF 버전으로, part-of-speech 에서의 품사 같이 GIFT 라는 태그 (한 발 더 나가면 GIFT-GIVER, GIFT-RECEIVER 를 이용해
  선물을 준사람과 받은사람의 정보까지) 를 사용해서 이것을 POS 태깅 문제처럼 해결해 볼 수 있을 것이다. 그 때 feature 는,</p>
<ul>
  <li>“이전 단어가 GIFT-RECEIVER 이고  그 이전 단어가 ‘gave’ 라면, 현재 단어는 GIFT 임”</li>
  <li>“다음 두 단어가 ‘for Christmas’ 면 현재 단어는 GIFT 임”</li>
</ul>

<p>와 같은 형태가 될 수 있을 것이다.</p>

<h3 id="마무리">마무리</h3>
<p>좀더 ‘랜덤한’ 생각을 나열하고 끝내고자 한다.</p>
<ul>
  <li>이 포스트에서는 CRF 를 사용한 그래픽 모델 프레임웍에 대한 내용은 일부러 스킵했다. 왜냐면 CRF 의 기본을 이해하는데는 큰 도움이 되지 않기 때문이다.
하지만 더 알고싶다면 Daphne Koller 가 공짜로 가르쳐주는 <a href="http://www.pgm-class.org" target="_blank">온라인 강좌</a>를 들어보시길.</li>
  <li>아니면 CRF 를 적용한 많은 NLP 응용 분야(POS 태깅이나 <a href="http://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">named entity extraction</a>등)에 관심이 있다면
Manning 과 Jurafsky 가 강의를 하고 있다. (링크가 있었는데 깨짐. http://www.nlp-class.org)</li>
  <li>또한 CRF/HMM 과 Logistic Regression/Naive Bayes 간의 유사점에 대해 조금 더 꾸며봤다. 아래 이미지를 참고바람.
<img src="/public/img/graph_model.png" alt="graph_model" /></li>
</ul>

<p>출처 : <a href="http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields" target="_blank">introduction to conditional random fields</a></p>


  </article>
</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/study/jsmath/tex/2017/11/29/js-math/">
            jsMath(TeX) 주요 문법
            <small>29 Nov 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/study/2017/11/29/gibbs-sampling/">
            Gibbs Sampling
            <small>29 Nov 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/study/2017/11/29/Monte-Carlo-Method/">
            Monte Carlo Method
            <small>29 Nov 2017</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>



      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
</html>
